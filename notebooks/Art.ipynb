{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5447df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src import config\n",
    "from src.utils import *\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762dac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1766499698.602162 2163400 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1\n",
      "W0000 00:00:1766499698.726754 2163856 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.749429 2163863 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.751994 2163857 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.752089 2163858 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.752129 2163861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.762509 2163863 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.765765 2163861 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.765841 2163857 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1766499698.779282 2163863 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import colorsys  \n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def get_rainbow_color(hue_offset, brightness=1.0):\n",
    "    r, g, b = colorsys.hsv_to_rgb(hue_offset, 1.0, brightness)\n",
    "    return (int(b * 255), int(g * 255), int(r * 255))\n",
    "\n",
    "def get_hand_coords(landmarks, image_shape):\n",
    "    h, w, c = image_shape\n",
    "    coords = []\n",
    "    for lm in landmarks.landmark:\n",
    "        coords.append((int(lm.x * w), int(lm.y * h)))\n",
    "    return coords\n",
    "\n",
    "def draw_artistic_trail(image, history_list, trace_lifetime, current_time, base_hue_offset):\n",
    "    \n",
    "    for i, snapshot in enumerate(history_list):\n",
    "        coords_curr, timestamp = snapshot\n",
    "        \n",
    "        age = current_time - timestamp\n",
    "        life_ratio = 1.0 - (age / trace_lifetime) \n",
    "        life_ratio = max(0, min(1, life_ratio))\n",
    "        \n",
    "        if life_ratio <= 0: continue\n",
    "\n",
    "        hue = (base_hue_offset + (i * 0.02)) % 1.0\n",
    "        color = get_rainbow_color(hue, brightness=life_ratio)\n",
    "        \n",
    "        thickness = int(4 * life_ratio) + 1 \n",
    "        \n",
    "        radius = int(3 * life_ratio)\n",
    "\n",
    "        for connection in mp_holistic.HAND_CONNECTIONS:\n",
    "            pt1 = coords_curr[connection[0]]\n",
    "            pt2 = coords_curr[connection[1]]\n",
    "            cv2.line(image, pt1, pt2, color, thickness)\n",
    "           \n",
    "            if radius > 0:\n",
    "                cv2.circle(image, pt1, radius, color, -1)\n",
    "                cv2.circle(image, pt2, radius, color, -1)\n",
    "        \n",
    "        if i > 0:\n",
    "            coords_prev = history_list[i-1][0]\n",
    "            for j in range(21):\n",
    "                pt_a = coords_prev[j]\n",
    "                pt_b = coords_curr[j]\n",
    "                cv2.line(image, pt_a, pt_b, color, thickness)\n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "\n",
    "history_right = [] \n",
    "history_left = [] \n",
    "\n",
    "trace_lifetime = 1.5\n",
    "sampling_rate = 2 \n",
    "frame_counter = 0\n",
    "global_hue = 0.0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        image, results = media_pipe_detection(frame, holistic)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        frame_counter += 1\n",
    "        global_hue = (global_hue + 0.01) % 1.0\n",
    "        \n",
    "        if results.right_hand_landmarks:\n",
    "            if frame_counter % sampling_rate == 0:\n",
    "                coords = get_hand_coords(results.right_hand_landmarks, image.shape)\n",
    "                history_right.append((coords, current_time))\n",
    "        \n",
    "        if results.left_hand_landmarks:\n",
    "            if frame_counter % sampling_rate == 0:\n",
    "                coords = get_hand_coords(results.left_hand_landmarks, image.shape)\n",
    "                history_left.append((coords, current_time))\n",
    "\n",
    "        history_right = [snap for snap in history_right if (current_time - snap[1]) < trace_lifetime]\n",
    "        history_left = [snap for snap in history_left if (current_time - snap[1]) < trace_lifetime]\n",
    "\n",
    "        draw_artistic_trail(image, history_right, trace_lifetime, current_time, global_hue)\n",
    "        draw_artistic_trail(image, history_left, trace_lifetime, current_time, global_hue + 0.5)\n",
    "\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
