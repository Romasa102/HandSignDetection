{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2098cfd5",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.utils import *\n",
    "from src import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('../datasets',config.TRAINING_DATAFILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be4310",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f35b8",
   "metadata": {},
   "source": [
    "## Data Separation\n",
    "Separate the data into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1318be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 30, 1662) (85, 3)\n",
      "(5, 30, 1662) (5, 3)\n"
     ]
    }
   ],
   "source": [
    "label_map = {label:num for num, label in enumerate(config.ACTIONS)}\n",
    "sequences, labels = [], []\n",
    "for action in config.ACTIONS:\n",
    "    for sequence in range(config.NO_SEQUENCES):\n",
    "        window = []\n",
    "        for frame_num in range(config.SEQUENCE_LENGTH):\n",
    "            npy_path = os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num))\n",
    "            res = np.load(npy_path)\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9715d2e",
   "metadata": {},
   "source": [
    "## Set the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982786c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77b0e8",
   "metadata": {},
   "source": [
    "## Define the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ac74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, return_sequences=True, activation=config.LSTM_ACTIVATION_FUNCTION, input_shape=(30, 1662), kernel_regularizer=l2(config.L2NORM)))\n",
    "model.add(LSTM(128, return_sequences=True, activation=config.LSTM_ACTIVATION_FUNCTION, kernel_regularizer=l2(config.L2NORM))) \n",
    "model.add(Dropout(config.DROPOUTRATE))\n",
    "model.add(LSTM(64, return_sequences=False, activation=config.LSTM_ACTIVATION_FUNCTION, kernel_regularizer=l2(config.L2NORM)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64, activation=config.DENSE_ACTIVATION_FUNCTION, kernel_regularizer=l2(config.L2NORM)))\n",
    "model.add(Dense(32, activation=config.DENSE_ACTIVATION_FUNCTION, kernel_regularizer=l2(config.L2NORM)))\n",
    "\n",
    "model.add(Dense(config.ACTIONS.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6823fb",
   "metadata": {},
   "source": [
    "## Configure the setting and start the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9756de",
   "metadata": {},
   "source": [
    "Configure the training setting using the setting in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=config.OPTIMIZER, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e3f12",
   "metadata": {},
   "source": [
    "Start the training based on those settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29551fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=config.EPOCHS, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf77c93",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8539f",
   "metadata": {},
   "source": [
    "Set the name of your model and run the code to save the created model as h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model1'\n",
    "\n",
    "model.save(os.path.join('..',config.MODEL_SAVE_DIRECTORY , \"{}.h5\".format(model_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf8ec6",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4d3dc",
   "metadata": {},
   "source": [
    "Show all the test data's predicted ansser and the actual answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b180435",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)\n",
    "for i in range(len(X_test)):\n",
    "    print(\"Predicted: {} , Actual: {}\".format(config.ACTIONS[np.argmax(res[i])], config.ACTIONS[np.argmax(y_test[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68843953",
   "metadata": {},
   "source": [
    "Get the confusion matrix and accuracy score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb36c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "multilabel_confusion_matrix(ytrue, yhat)\n",
    "accuracy_score(ytrue, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
