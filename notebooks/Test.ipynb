{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff56fe9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf633fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src import config\n",
    "from src.utils import *\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8177cb",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "Load the model and check the model's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596675 (2.28 MB)\n",
      "Trainable params: 596675 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../'+ config.MODEL_DIRECTORY)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5894df4",
   "metadata": {},
   "source": [
    "# Real Time test\n",
    "Using the loaded model, this code would do the inference in real time.\n",
    "It would show the detected action in text.\n",
    "Press the button 'Q' to quit the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42919a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1765753819.886734 6314339 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 90.5), renderer: Apple M1\n",
      "W0000 00:00:1765753820.167616 6321150 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.227940 6321150 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.233682 6321151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.233604 6321152 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.233879 6321155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.250938 6321151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.259013 6321155 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.265341 6321152 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1765753820.309014 6321151 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 657ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sequence) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m30\u001b[39m:\n\u001b[1;32m     19\u001b[0m     res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mexpand_dims(sequence, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mactions\u001b[49m[np\u001b[38;5;241m.\u001b[39margmax(res)])\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res[np\u001b[38;5;241m.\u001b[39margmax(res)] \u001b[38;5;241m>\u001b[39m threshold: \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentence) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'actions' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "threshold = 0.4\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image, results = media_pipe_detection(frame, holistic)\n",
    "        draw_landmarks(image, results)\n",
    "        \n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            \n",
    "            if res[np.argmax(res)] > threshold: \n",
    "                \n",
    "                if len(sentence) > 0: \n",
    "                    if actions[np.argmax(res)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "            \n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "            \n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "        \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
